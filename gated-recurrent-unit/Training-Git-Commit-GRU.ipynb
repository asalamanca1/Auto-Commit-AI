{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRU Model Training for Git Commit Message Generation\n",
        "\n",
        "This notebook trains a **Gated Recurrent Unit (GRU)** language model to generate Git commit messages from Git diffs. It uses a custom-trained Byte Pair Encoding (BPE) tokenizer and follows a causal language modeling objective.\n",
        "\n",
        "---\n",
        "\n",
        "### Overview\n",
        "\n",
        "1. **BPE tokenizer Loading**  \n",
        "   Loads a trained `custom_bpe_tokenizer.json` file and registers special tokens:\n",
        "   - `<sos>` (start-of-sequence)\n",
        "   - `<endOfDiff>` (separator between diff and message)\n",
        "   - `<endOfCommitMessage>` (end token)\n",
        "   - `<pad>` (used for batching)\n",
        "\n",
        "2. **Model Architecture**  \n",
        "   - 4-layer GRU with:\n",
        "     - 512-dimensional embeddings\n",
        "     - 512 hidden units per layer\n",
        "     - Dropout of 0.2\n",
        "     - Weight tying between embedding and output layer\n",
        "\n",
        "3. **Dataset Setup**  \n",
        "   Each input sample is tokenized as: \n",
        "   `<sos> + diff + <endOfDiff> + commit_message + <endOfCommitMessage>`\n",
        "\n",
        "\n",
        "4. **Training Loop**\n",
        "- Uses `CrossEntropyLoss` (ignoring padding)\n",
        "- `AdamW` optimizer with weight decay\n",
        "- Clip gradient norm to 1.0\n",
        "- Logs both training and validation loss\n",
        "- Plots learning curves as `gru_loss_curve.png`\n",
        "\n",
        "---\n",
        "\n",
        "### File Requirements\n",
        "\n",
        "- `custom_bpe_tokenizer.json`: Path to your trained tokenizer\n",
        "- `data/cleaned_python_commit_dataset.csv`: Must contain `diff` and `commit_message` columns\n",
        "\n",
        "> **Make sure the CSV path is correct** and matches your project structure.\n",
        "\n",
        "---\n",
        "\n",
        "### Output\n",
        "\n",
        "- Trained model weights saved to:  \n",
        "`trained_model/gru_model.pt`\n",
        "\n",
        "- Loss plot image saved to:  \n",
        "`gru_loss_curve.png`\n",
        "\n",
        "This notebook serves as the baseline RNN-based model in comparison to the GPT-2 transformer model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njof3cPdnSHn",
        "outputId": "7fde762a-459c-4009-a5ef-d32abf9f24e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 training: 100%|██████████| 1914/1914 [11:08<00:00,  2.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Train Loss: 4.4200\n",
            "Epoch 1 Val Loss: 3.4640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Train Loss: 3.3897\n",
            "Epoch 2 Val Loss: 3.0875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Train Loss: 3.1197\n",
            "Epoch 3 Val Loss: 2.8997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Train Loss: 2.9634\n",
            "Epoch 4 Val Loss: 2.7786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Train Loss: 2.8521\n",
            "Epoch 5 Val Loss: 2.6920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Train Loss: 2.7654\n",
            "Epoch 6 Val Loss: 2.6172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Train Loss: 2.6941\n",
            "Epoch 7 Val Loss: 2.5575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8 training: 100%|██████████| 1914/1914 [11:07<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Train Loss: 2.6334\n",
            "Epoch 8 Val Loss: 2.5054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Train Loss: 2.5808\n",
            "Epoch 9 Val Loss: 2.4601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Train Loss: 2.5319\n",
            "Epoch 10 Val Loss: 2.4185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Train Loss: 2.4889\n",
            "Epoch 11 Val Loss: 2.3821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Train Loss: 2.4509\n",
            "Epoch 12 Val Loss: 2.3511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Train Loss: 2.4166\n",
            "Epoch 13 Val Loss: 2.3232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14 training: 100%|██████████| 1914/1914 [11:07<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Train Loss: 2.3850\n",
            "Epoch 14 Val Loss: 2.2960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Train Loss: 2.3560\n",
            "Epoch 15 Val Loss: 2.2713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Train Loss: 2.3289\n",
            "Epoch 16 Val Loss: 2.2500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17 training: 100%|██████████| 1914/1914 [11:06<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Train Loss: 2.3046\n",
            "Epoch 17 Val Loss: 2.2263\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18 training: 100%|██████████| 1914/1914 [11:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Train Loss: 2.2811\n",
            "Epoch 18 Val Loss: 2.2096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19 training: 100%|██████████| 1914/1914 [11:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Train Loss: 2.2596\n",
            "Epoch 19 Val Loss: 2.1935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20 training: 100%|██████████| 1914/1914 [11:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Train Loss: 2.2394\n",
            "Epoch 20 Val Loss: 2.1750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21 training: 100%|██████████| 1914/1914 [11:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Train Loss: 2.2198\n",
            "Epoch 21 Val Loss: 2.1612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22 training: 100%|██████████| 1914/1914 [11:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Train Loss: 2.2017\n",
            "Epoch 22 Val Loss: 2.1454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23 training: 100%|██████████| 1914/1914 [11:03<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Train Loss: 2.1847\n",
            "Epoch 23 Val Loss: 2.1311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Train Loss: 2.1686\n",
            "Epoch 24 Val Loss: 2.1189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Train Loss: 2.1529\n",
            "Epoch 25 Val Loss: 2.1066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26 training: 100%|██████████| 1914/1914 [11:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Train Loss: 2.1382\n",
            "Epoch 26 Val Loss: 2.0980\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27 training: 100%|██████████| 1914/1914 [11:20<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Train Loss: 2.1239\n",
            "Epoch 27 Val Loss: 2.0851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28 training: 100%|██████████| 1914/1914 [11:16<00:00,  2.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Train Loss: 2.1107\n",
            "Epoch 28 Val Loss: 2.0759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29 training: 100%|██████████| 1914/1914 [11:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Train Loss: 2.0974\n",
            "Epoch 29 Val Loss: 2.0653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30 training: 100%|██████████| 1914/1914 [11:09<00:00,  2.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Train Loss: 2.0848\n",
            "Epoch 30 Val Loss: 2.0576\n",
            "Saved plot to gru_loss_curve.png\n",
            "trained_model/gru_model.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from tqdm import tqdm\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import AdamW\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load custom BPE tokenizer\n",
        "custom_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_file=\"custom_bpe_tokenizer.json\"\n",
        ")\n",
        "custom_tokenizer.add_special_tokens({\n",
        "    \"pad_token\": \"<pad>\",\n",
        "    \"eos_token\": \"<endOfCommitMessage>\",\n",
        "    \"bos_token\": \"<sos>\"\n",
        "})\n",
        "custom_tokenizer.add_tokens([\"<endOfDiff>\"])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# GRU Language Model\n",
        "class GRULanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=512, hidden_dim=512, num_layers=4, dropout=0.2, pad_id=0):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_id)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "                          dropout=dropout if num_layers > 1 else 0.0)\n",
        "        self.lm_head = nn.Linear(hidden_dim, vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.embed.weight  # weight tying\n",
        "\n",
        "    def forward(self, input_ids, hidden=None):\n",
        "        x = self.drop(self.embed(input_ids))\n",
        "        out, new_h = self.gru(x, hidden)\n",
        "        logits = self.lm_head(out)\n",
        "        return logits, new_h\n",
        "\n",
        "# Dataset class\n",
        "class GitDiffDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sep = \"<endOfDiff>\"\n",
        "        self.eos = \"<endOfCommitMessage>\"\n",
        "        self.bos = \"<sos>\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        diff, msg = map(str, self.data[idx])\n",
        "        full = self.bos + diff + self.sep + msg + self.eos\n",
        "        ids = self.tokenizer.encode(full)\n",
        "        return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "# Collate for batching\n",
        "def collate_fn(batch):\n",
        "    max_len = min(512, max(len(seq) for seq in batch))  # truncate long samples\n",
        "    pad_id = custom_tokenizer.pad_token_id\n",
        "    padded = [F.pad(seq, (0, max_len - len(seq)), value=pad_id) for seq in batch]\n",
        "    return torch.stack(padded)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, val_loader, epochs=30, lr=2e-4, device='cuda'):\n",
        "    model.to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=custom_tokenizer.pad_token_id)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} training\"):\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits, _ = model(batch[:, :-1])\n",
        "            loss = criterion(logits.reshape(-1, logits.size(-1)), batch[:, 1:].reshape(-1))\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f\"Epoch {epoch+1} Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                logits, _ = model(batch[:, :-1])\n",
        "                loss = criterion(logits.reshape(-1, logits.size(-1)), batch[:, 1:].reshape(-1))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Plot learning curves\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "    plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"GRU Training vs Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"gru_loss_curve.png\")\n",
        "    print(\"Saved plot to gru_loss_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"data/cleaned_python_commit_dataset.csv\")\n",
        "data = list(zip(df[\"diff\"].astype(str), df[\"commit_message\"].astype(str)))\n",
        "random.shuffle(data)\n",
        "split_idx = int(0.8 * len(data))\n",
        "train_data, val_data = data[:split_idx], data[split_idx:]\n",
        "# train_data, val_data = data[:split_idx], data[:split_idx]\n",
        "\n",
        "train_loader = DataLoader(GitDiffDataset(train_data, custom_tokenizer), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(GitDiffDataset(val_data, custom_tokenizer), batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "vocab_size = len(custom_tokenizer)\n",
        "# Initialize and train the model\n",
        "model = GRULanguageModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=512,\n",
        "    hidden_dim=512,\n",
        "    num_layers=4,\n",
        "    dropout=0.2,\n",
        "    pad_id=custom_tokenizer.pad_token_id\n",
        ")\n",
        "\n",
        "train_model(model, train_loader, val_loader, epochs=30, device=device)\n",
        "\n",
        "# Save the trained weights\n",
        "os.makedirs(\"trained_model\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"trained_model/gru_model.pt\")\n",
        "print(\"trained_model/gru_model.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exrEYOKfzuNt"
      },
      "source": [
        "## Run an inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2La-v3iyAOB",
        "outputId": "28185b09-bb27-42d6-b7a0-255f227998ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Commit Message:\n",
            " 't be used for the current_run_and_run_run.py\n",
            "\n",
            "This is a bug to avoid a bug that is not used in the\n",
            "and the main function.\n",
            "\n",
            "This reverts commit 3a4a0a0\n"
          ]
        }
      ],
      "source": [
        "# Inference function for GRU model\n",
        "def generate_commit_message(model, tokenizer, git_diff, max_new_tokens=50, device='cuda'):\n",
        "    model.eval()\n",
        "    sep_token = \"<endOfDiff>\"\n",
        "    eos_token = \"<endOfCommitMessage>\"\n",
        "    bos_token = \"<sos>\"\n",
        "\n",
        "    input_text = bos_token + git_diff + sep_token\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    eos_id = tokenizer.encode(eos_token)[0]\n",
        "\n",
        "    generated = input_ids\n",
        "    hidden = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, hidden = model(generated[:, -1:], hidden)\n",
        "            next_id = logits[0, -1].argmax(dim=-1).item()\n",
        "            generated = torch.cat([generated, torch.tensor([[next_id]], device=device)], dim=1)\n",
        "            if next_id == eos_id:\n",
        "                break\n",
        "\n",
        "    decoded = tokenizer.decode(generated[0].tolist())\n",
        "    return decoded.split(sep_token)[1].replace(eos_token, \"\").strip()\n",
        "\n",
        "# Example Git diff input\n",
        "sample_diff = \"\"\"diff --git a/config.py b/config.py\n",
        "index abc123..def456 100644\n",
        "--- a/config.py\n",
        "+++ b/config.py\n",
        "@@ -1,5 +1,6 @@\n",
        " DEBUG = False\n",
        "+LOGGING_ENABLED = True\n",
        "\"\"\"\n",
        "\n",
        "# Load model and run inference\n",
        "model.load_state_dict(torch.load(\"trained_model/gru_model.pt\", map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "generated_msg = generate_commit_message(model, custom_tokenizer, sample_diff, device=device)\n",
        "print(\"Generated Commit Message:\\n\", generated_msg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download weights and loss curve graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MTwyNpZopMZ6",
        "outputId": "08b63fed-616e-48ab-dc21-14b9377fcf5b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a45ccdcc-5e82-4e1f-b6e7-e88c8053a8b6\", \"gru_model.pt\", 123524068)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download cleaned dataset\n",
        "files.download('trained_model/gru_model.pt')\n",
        "files.download('gru_loss_curve.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "undefined.undefined.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
